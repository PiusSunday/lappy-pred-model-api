{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "717abb98",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "079327fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7db9ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.1\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a36b90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0d30266",
   "metadata": {},
   "source": [
    "## Importing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "685e5091",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset= pd.read_excel('last_time_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3fc4b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(254, 16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67e0c48",
   "metadata": {},
   "source": [
    "## Select the important columns necessary for training/building our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c84372b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[['BRAND', 'CPU BRAND', 'CPU CORE', 'CPU GENERATION', 'CPU FAMILY', 'RAM SIZE', 'RAM(DDR) TYPE', 'DISK TYPE', 'SSD SIZE',\n",
    "                   'HDD SIZE', 'GPU BRAND', 'GPU TYPE', 'SCREEN SIZE', 'SCREEN RESOLUTION', 'STATE', 'PRICE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739303e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb445b38",
   "metadata": {},
   "source": [
    "## Convert the DataType of categorical datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2376461c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CATEGORICALS\n",
    "dataset[\"BRAND\"] = dataset[\"BRAND\"].astype(\"str\")\n",
    "dataset[\"CPU BRAND\"] = dataset[\"CPU BRAND\"].astype(\"str\")\n",
    "dataset[\"CPU CORE\"] = dataset[\"CPU CORE\"].astype(\"str\")\n",
    "dataset[\"CPU FAMILY\"] = dataset[\"CPU FAMILY\"].astype(\"str\")\n",
    "dataset[\"DISK TYPE\"] = dataset[\"DISK TYPE\"].astype(\"str\")\n",
    "dataset[\"GPU BRAND\"] = dataset[\"GPU BRAND\"].astype(\"str\")\n",
    "dataset[\"GPU TYPE\"] = dataset[\"GPU TYPE\"].astype(\"str\")\n",
    "dataset[\"SCREEN RESOLUTION\"] = dataset[\"SCREEN RESOLUTION\"].astype(\"str\")\n",
    "dataset[\"STATE\"] = dataset[\"STATE\"].astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b1fe62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e21d493a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "437902b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['ACER', 'Intel', 'Core i3', ..., 'HD', 'USED', 79000],\n",
       "       ['ACER', 'Intel', 'Core i3', ..., 'HD', 'USED', 79000],\n",
       "       ['ACER', 'Intel', 'Core i3', ..., 'FHD', 'USED', 88000],\n",
       "       ...,\n",
       "       ['LENOVO', 'AMD', 'Ryzen 7', ..., 'FHD', 'USED', 112000],\n",
       "       ['LENOVO', 'AMD', 'Ryzen 7', ..., 'FHD', 'USED', 135000],\n",
       "       ['LENOVO', 'AMD', 'Ryzen 7', ..., 'FHD', 'USED', 135000]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb08b85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1280c625",
   "metadata": {},
   "source": [
    "## Selecting the X and y columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e91135e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop('PRICE', axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f4d75a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(254, 15)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "348d96f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset.PRICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5e207dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(254, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.values.reshape((254,1))\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1b6e52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eea0c0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f548fe8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8fc7404",
   "metadata": {},
   "source": [
    "## Splitting data into Train and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9933a7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3c388a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a431972d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7556c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d800d1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_data = dataset[['BRAND', 'CPU BRAND', 'CPU CORE', 'CPU FAMILY', 'DISK TYPE',\n",
    "               'GPU BRAND', 'GPU TYPE', 'SCREEN RESOLUTION', 'STATE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "012e71a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['BRAND', 'CPU BRAND', 'CPU CORE', 'CPU FAMILY', 'DISK TYPE',\n",
    "               'GPU BRAND', 'GPU TYPE', 'SCREEN RESOLUTION', 'STATE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e28ba59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b94cf610",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_data = dataset[['CPU GENERATION', 'RAM SIZE', 'RAM(DDR) TYPE', 'SSD SIZE', 'HDD SIZE', 'SCREEN SIZE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a73a7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = ['CPU GENERATION', 'RAM SIZE', 'RAM(DDR) TYPE', 'SSD SIZE', 'HDD SIZE', 'SCREEN SIZE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ca7245",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5788dec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21c4396",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "226447f7",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "475f0c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a16d8bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c246c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed07672",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43363713",
   "metadata": {},
   "source": [
    "## Normalization and Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3647b4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline([\n",
    "    (\"MinMax_Scaler\", MinMaxScaler()),\n",
    "    ('Standered_Scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d709f20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c6cbf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7935ff81",
   "metadata": {},
   "source": [
    "## ColumnTransformer and OneHotEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82684d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_trans = ColumnTransformer(transformers = [\n",
    "    (\"numerical\", num_pipeline, numerical_columns),\n",
    "    (\"categorical\", OneHotEncoder(sparse = False, handle_unknown='ignore'), categorical_columns),\n",
    "    ], remainder = 'passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc7de46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2b323d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e662bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2dde5632",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6670289",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import explained_variance_score, mean_absolute_error, r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "812fd18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import Lars\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LassoLars\n",
    "from sklearn.linear_model import LassoLarsCV\n",
    "from sklearn.linear_model import LassoLarsIC\n",
    "from sklearn.linear_model import OrthogonalMatchingPursuit\n",
    "from sklearn.linear_model import ARDRegression\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.linear_model import MultiTaskElasticNet\n",
    "from sklearn.linear_model import MultiTaskLasso\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "from sklearn.linear_model import PassiveAggressiveRegressor\n",
    "from sklearn.linear_model import TheilSenRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d887dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressors = [\n",
    "    Ridge(),\n",
    "    RidgeCV(),\n",
    "    LinearRegression(),\n",
    "    SGDRegressor(),\n",
    "    ElasticNet(),\n",
    "    Lars(),\n",
    "    Lasso(),\n",
    "    LassoLars(),\n",
    "    LassoLarsCV(),\n",
    "    LassoLarsIC(),\n",
    "    OrthogonalMatchingPursuit(),\n",
    "    ARDRegression(),\n",
    "    BayesianRidge(),\n",
    "    MultiTaskElasticNet(),\n",
    "    MultiTaskLasso(),\n",
    "    HuberRegressor(),\n",
    "    RANSACRegressor(),\n",
    "    PassiveAggressiveRegressor(),\n",
    "    TheilSenRegressor()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ba3a4085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge()\n",
      "\t Training Time: 0.037s\n",
      "\t Prediction Time: 0.000s\n",
      "\t Explained Variance Score: 0.8693716553165736\n",
      "\t Mean Absolute Error: 11293.331735078144\n",
      "\t Mean Squared Error: 228015503.55729485\n",
      "\t Root Mean Squared Error: 15100.182235896851\n",
      "\t R2 Score: 0.8677919202632969\n",
      "\n",
      "RidgeCV()\n",
      "\t Training Time: 0.069s\n",
      "\t Prediction Time: 0.000s\n",
      "\t Explained Variance Score: 0.8693716553165933\n",
      "\t Mean Absolute Error: 11293.331735078702\n",
      "\t Mean Squared Error: 228015503.5572494\n",
      "\t Root Mean Squared Error: 15100.182235895347\n",
      "\t R2 Score: 0.8677919202633233\n",
      "\n",
      "LinearRegression()\n",
      "\t Training Time: 0.027s\n",
      "\t Prediction Time: 0.000s\n",
      "\t Explained Variance Score: -9.14323916113448e+19\n",
      "\t Mean Absolute Error: 122575877364934.52\n",
      "\t Mean Squared Error: 1.6042894550690312e+29\n",
      "\t Root Mean Squared Error: 400535823000768.7\n",
      "\t R2 Score: -9.302000297678124e+19\n",
      "\n",
      "SGDRegressor()\n",
      "\t Training Time: 0.040s\n",
      "\t Prediction Time: 0.000s\n",
      "\t Explained Variance Score: 0.8680198849943278\n",
      "\t Mean Absolute Error: 11717.500642472405\n",
      "\t Mean Squared Error: 230151240.29373416\n",
      "\t Root Mean Squared Error: 15170.736313499558\n",
      "\t R2 Score: 0.8665535761667658\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=4.959e+02, with an active set of 9 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.607e+02, with an active set of 23 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=1.412e+02, with an active set of 29 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=1.385e+02, with an active set of 30 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=1.162e+02, with an active set of 39 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=1.869e+04, with an active set of 48 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=2.302e+04, with an active set of 51 regressors, and the smallest cholesky pivot element being 9.424e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=1.450e+04, with an active set of 52 regressors, and the smallest cholesky pivot element being 9.424e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 68 iterations, i.e. alpha=7.443e+04, with an active set of 54 regressors, and the smallest cholesky pivot element being 9.541e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=1.569e+04, with an active set of 55 regressors, and the smallest cholesky pivot element being 9.657e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=1.046e+04, with an active set of 55 regressors, and the smallest cholesky pivot element being 9.657e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=6.847e+03, with an active set of 55 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=2.940e+03, with an active set of 55 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=2.766e+03, with an active set of 55 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=1.627e+03, with an active set of 56 regressors, and the smallest cholesky pivot element being 9.541e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=8.873e+01, with an active set of 56 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=5.348e+02, with an active set of 57 regressors, and the smallest cholesky pivot element being 9.771e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=3.929e+01, with an active set of 57 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=3.510e+01, with an active set of 57 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=4.489e+00, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.333e+09, tolerance: 2.872e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet()\n",
      "\t Training Time: 0.023s\n",
      "\t Prediction Time: 0.000s\n",
      "\t Explained Variance Score: 0.6767089242251345\n",
      "\t Mean Absolute Error: 18904.746076850555\n",
      "\t Mean Squared Error: 563743605.5792098\n",
      "\t Root Mean Squared Error: 23743.285484094442\n",
      "\t R2 Score: 0.6731298600546929\n",
      "\n",
      "Lars()\n",
      "\t Training Time: 0.053s\n",
      "\t Prediction Time: 0.000s\n",
      "\t Explained Variance Score: -5.915406282351776e+31\n",
      "\t Mean Absolute Error: 9.318082381246702e+19\n",
      "\t Mean Squared Error: 1.1070399056118678e+41\n",
      "\t Root Mean Squared Error: 3.327220920846507e+20\n",
      "\t R2 Score: -6.418845114892346e+31\n",
      "\n",
      "Lasso()\n",
      "\t Training Time: 0.039s\n",
      "\t Prediction Time: 0.000s\n",
      "\t Explained Variance Score: 0.8402751141946687\n",
      "\t Mean Absolute Error: 12094.382561310356\n",
      "\t Mean Squared Error: 284761594.52502984\n",
      "\t Root Mean Squared Error: 16874.880578096836\n",
      "\t R2 Score: 0.8348893693298541\n",
      "\n",
      "LassoLars()\n",
      "\t Training Time: 0.035s\n",
      "\t Prediction Time: 0.000s\n",
      "\t Explained Variance Score: 0.795161511256328\n",
      "\t Mean Absolute Error: 14285.67205888025\n",
      "\t Mean Squared Error: 362734279.6722283\n",
      "\t Root Mean Squared Error: 19045.584256520677\n",
      "\t R2 Score: 0.7896792024140096\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=4.959e+02, with an active set of 9 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.607e+02, with an active set of 23 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.607e+02, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=1.390e+02, with an active set of 26 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=1.337e+02, with an active set of 26 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 36 iterations, alpha=1.089e+02, previous alpha=9.596e+01, with an active set of 31 regressors.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsCV())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=4.903e+02, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=4.181e+02, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=4.077e+02, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=2.027e+02, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=2.005e+02, with an active set of 21 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 34 iterations, alpha=1.605e+02, previous alpha=1.488e+02, with an active set of 25 regressors.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.272e+02, with an active set of 24 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=1.035e+02, with an active set of 26 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=8.834e+01, with an active set of 28 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=8.834e+01, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=8.634e+01, with an active set of 28 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=4.279e+01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=4.279e+01, with an active set of 38 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=4.182e+01, with an active set of 38 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=3.966e+01, with an active set of 38 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 45 iterations, alpha=4.124e+01, previous alpha=3.690e+01, with an active set of 40 regressors.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.796e+02, with an active set of 22 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.796e+02, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=1.185e+02, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=1.185e+02, with an active set of 28 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=1.126e+02, with an active set of 28 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=8.072e+01, with an active set of 30 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=4.922e+01, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=4.922e+01, with an active set of 33 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 40 iterations, alpha=7.150e+01, previous alpha=4.913e+01, with an active set of 33 regressors.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=5.920e+01, with an active set of 29 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=5.920e+01, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=5.062e+01, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=4.933e+01, with an active set of 30 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=4.097e+01, with an active set of 32 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=2.339e+01, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=2.137e+01, with an active set of 36 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=1.891e+01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=1.771e+01, with an active set of 38 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=1.095e+01, with an active set of 43 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=9.794e+00, with an active set of 43 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=7.933e+00, with an active set of 44 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=7.539e+00, with an active set of 44 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=6.308e+00, with an active set of 45 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=5.906e+00, with an active set of 45 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=5.863e+00, with an active set of 45 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 56 iterations, alpha=1.216e+01, previous alpha=4.892e+00, with an active set of 45 regressors.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.842e+02, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.711e+02, with an active set of 21 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.580e+02, with an active set of 22 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.580e+02, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.270e+02, with an active set of 25 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.240e+02, with an active set of 25 regressors, and the smallest cholesky pivot element being 8.878e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 31 iterations, alpha=1.057e+02, previous alpha=8.782e+01, with an active set of 28 regressors.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=4.959e+02, with an active set of 9 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.607e+02, with an active set of 23 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.607e+02, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=1.390e+02, with an active set of 26 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=1.337e+02, with an active set of 26 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=4.959e+02, with an active set of 9 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.607e+02, with an active set of 23 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.607e+02, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=1.390e+02, with an active set of 26 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=1.337e+02, with an active set of 26 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoLarsCV()\n",
      "\t Training Time: 0.116s\n",
      "\t Prediction Time: 0.000s\n",
      "\t Explained Variance Score: 0.7892395542156587\n",
      "\t Mean Absolute Error: 14602.443176533146\n",
      "\t Mean Squared Error: 372879737.46052617\n",
      "\t Root Mean Squared Error: 19310.09418569796\n",
      "\t R2 Score: 0.7837966572742506\n",
      "\n",
      "LassoLarsIC()\n",
      "\t Training Time: 0.034s\n",
      "\t Prediction Time: 0.000s\n",
      "\t Explained Variance Score: 0.7933816348335134\n",
      "\t Mean Absolute Error: 14376.03459008997\n",
      "\t Mean Squared Error: 365841087.50946075\n",
      "\t Root Mean Squared Error: 19126.97277431692\n",
      "\t R2 Score: 0.7878778113161966\n",
      "\n",
      "OrthogonalMatchingPursuit()\n",
      "\t Training Time: 0.019s\n",
      "\t Prediction Time: 0.000s\n",
      "\t Explained Variance Score: 0.6742594687895598\n",
      "\t Mean Absolute Error: 19766.43244010974\n",
      "\t Mean Squared Error: 577790507.0654249\n",
      "\t Root Mean Squared Error: 24037.273286823216\n",
      "\t R2 Score: 0.6649851775977103\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:679: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 36 iterations, alpha=1.089e+02, previous alpha=9.596e+01, with an active set of 31 regressors.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARDRegression()\n",
      "\t Training Time: 0.349s\n",
      "\t Prediction Time: 0.000s\n",
      "\t Explained Variance Score: 0.804772947070596\n",
      "\t Mean Absolute Error: 13589.894299600754\n",
      "\t Mean Squared Error: 337246936.9950775\n",
      "\t Root Mean Squared Error: 18364.284276689836\n",
      "\t R2 Score: 0.8044572880282218\n",
      "\n",
      "BayesianRidge()\n",
      "\t Training Time: 0.026s\n",
      "\t Prediction Time: 0.000s\n",
      "\t Explained Variance Score: 0.8691038274513296\n",
      "\t Mean Absolute Error: 11326.193462641426\n",
      "\t Mean Squared Error: 228352236.82170227\n",
      "\t Root Mean Squared Error: 15111.328095892242\n",
      "\t R2 Score: 0.8675966753892588\n",
      "\n",
      "MultiTaskElasticNet()\n",
      "\t Training Time: 0.019s\n",
      "\t Prediction Time: 0.000s\n",
      "\t Explained Variance Score: 0.6767089242251343\n",
      "\t Mean Absolute Error: 18904.746076850563\n",
      "\t Mean Squared Error: 563743605.57921\n",
      "\t Root Mean Squared Error: 23743.285484094446\n",
      "\t R2 Score: 0.6731298600546927\n",
      "\n",
      "MultiTaskLasso()\n",
      "\t Training Time: 0.049s\n",
      "\t Prediction Time: 0.000s\n",
      "\t Explained Variance Score: 0.8402751141946889\n",
      "\t Mean Absolute Error: 12094.38256131032\n",
      "\t Mean Squared Error: 284761594.52498734\n",
      "\t Root Mean Squared Error: 16874.880578095577\n",
      "\t R2 Score: 0.8348893693298787\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:2504: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1332924115.3802567, tolerance: 28722552.305418726\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HuberRegressor()\n",
      "\t Training Time: 0.070s\n",
      "\t Prediction Time: 0.000s\n",
      "\t Explained Variance Score: 0.8526262922629904\n",
      "\t Mean Absolute Error: 11820.125038130236\n",
      "\t Mean Squared Error: 264711742.16941774\n",
      "\t Root Mean Squared Error: 16269.964418197655\n",
      "\t R2 Score: 0.8465146861946515\n",
      "\n",
      "RANSACRegressor()\n",
      "\t Training Time: 0.229s\n",
      "\t Prediction Time: 0.000s\n",
      "\t Explained Variance Score: -3.090379387188738e+22\n",
      "\t Mean Absolute Error: 1357349660006885.2\n",
      "\t Mean Squared Error: 5.514128978269563e+31\n",
      "\t Root Mean Squared Error: 7425718132456660.0\n",
      "\t R2 Score: -3.197205419211084e+22\n",
      "\n",
      "PassiveAggressiveRegressor()\n",
      "\t Training Time: 0.077s\n",
      "\t Prediction Time: 0.000s\n",
      "\t Explained Variance Score: 0.7388275046452302\n",
      "\t Mean Absolute Error: 15724.184878388465\n",
      "\t Mean Squared Error: 471794110.5255156\n",
      "\t Root Mean Squared Error: 21720.822049948194\n",
      "\t R2 Score: 0.7264440688876627\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\parad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheilSenRegressor()\n",
      "\t Training Time: 11.776s\n",
      "\t Prediction Time: 0.000s\n",
      "\t Explained Variance Score: 0.87197949676299\n",
      "\t Mean Absolute Error: 11251.757318465236\n",
      "\t Mean Squared Error: 225174983.018087\n",
      "\t Root Mean Squared Error: 15005.83163367119\n",
      "\t R2 Score: 0.8694389125076071\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# head = 10\n",
    "for model in regressors:    # [:head]:\n",
    "    start = time()\n",
    "    \n",
    "    \n",
    "    pipe = Pipeline([\n",
    "    ('step1', column_trans),\n",
    "    ('step2', model)\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    train_time = time() - start\n",
    "    start = time()\n",
    "    predict_time = time()-start\n",
    "    \n",
    "    y_pred = pipe.predict(X_test)\n",
    "    \n",
    "    print(model)\n",
    "    print(\"\\t Training Time: %0.3fs\" % train_time)\n",
    "    print(\"\\t Prediction Time: %0.3fs\" % predict_time)\n",
    "    print(\"\\t Explained Variance Score:\", explained_variance_score(y_test, y_pred))\n",
    "    print(\"\\t Mean Absolute Error:\", mean_absolute_error(y_test, y_pred))\n",
    "    print(\"\\t Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
    "    print(\"\\t Root Mean Squared Error:\", mean_squared_error(y_test, y_pred, squared = False))\n",
    "    print(\"\\t R2 Score:\", r2_score(y_test, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1ea25e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
